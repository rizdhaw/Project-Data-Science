{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid black 2px; padding: 20px\">\n",
    "\n",
    "# Reviewer's feedback v.1\n",
    "\n",
    "**Halo Rizdha**\n",
    "    \n",
    "**Greetings from Chamdani**\n",
    "\n",
    "Terima kasih telah mengirimkan project kamu dengan ini kamu sudah memulai sebuah langkah yang luar biasa saat ini. Disini saya akan mereview proyek kamu ya.\n",
    "\n",
    "Saya akan memberikan beberapa komentar dan feedback seperti dibawah ini, **mohon jangan dipindah, dirubah, maupun dihapus ya :).**\n",
    "    \n",
    "> Mohon diperhatikan bahwa apabila ada temuan atau kesalahan yang sama namun tidak ada komentar perbaikan disana, itu berarti kamu masih tetap harus memperbaikinya yaa.\n",
    "\n",
    "Komentar yang saya berikan akan muncul dalam warna hijau, kuning, atau pun merah seperti ini:\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.*</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Bagus, semua berjalan lancar.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Chamdani's comment v.*</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Ada beberapa catatan.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Chamdani's comment v.*</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Perlu beberapa perbaikan.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Chamdani's info v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Catatan umum:\n",
    "* Fungsi `print` tidak diperlukan untuk mencetak suatu nilai\n",
    "* Lebih baik tulis kode pada bagian akhir cell code untuk menampilkan output tanpa `print`\n",
    "* Perintah soal yang ada dalam tanda kurung siku `[...]` sebaiknya dihilangkan\n",
    "* Sangat disarankan untuk menggunakan cell markdown untuk memberikan deskripsi temuan atau kesimpulan.\n",
    "* Tidak disarankan menggunakan cell code untuk memberikan penjelasan / deskripsi.\n",
    "* Untuk menghindari galat pada notebook project kamu. Batasi jumlah output yang dikeluarkan setiap kode dengan batas max 10 baris data.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"border:solid gray 5px; padding: 20px\" class=\"alert alert-warning\">\n",
    "\n",
    "**INGATLAH** \n",
    "* Project kamu tidak akan bisa diterima bila kamu masih memiliki feedback berwarna merah. \n",
    "* Kamu hanya memiliki 3 kali kesempatan iterasi submission disetiap projectnya \n",
    "* Jika merasa kesulitan kamu dapat menuliskan responmu atas feedback saya menggunakan blok markdown warna biru dan kamu bisa mengirimkan project pada submission selanjutnya untuk mendapatkan jawaban / respon dari saya segera yaa\n",
    "\n",
    "Kamu dapat menjawab saya dengan menggunakan blok berwarna biru seperti ini\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Student answer</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Siap kak.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid black 2px; padding: 20px\" class=\"alert alert-success\">\n",
    "    \n",
    "# General feedback v.1 *Project Accepted*\n",
    "\n",
    "Terima kasih banyak telah mengirimkan proyek Anda! \n",
    "<br>\n",
    "    \n",
    "Secara keseluruhan, proyek Anda **SANGAT** mengesankan. Semoga apa yang kamu pelajari dalam project ini dapat membantu meningkatkan kemampuanmu. Pertahankan apa yang sudah bagus, dan tingkatkan apa yang menurutmu masih perlu ditingkatkan. Semoga berhasil pada project selanjutnya yaa :)\n",
    "\n",
    "**TETAP SEMANGAT!!**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- Deskripsi Proyek\n",
    "- EDA\n",
    "- Data Separation\n",
    "- Model Training & Validation\n",
    "- Testing\n",
    "- General Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deskripsi Proyek\n",
    "\n",
    "Nasabah Bank Beta pergi meninggalkan perusahaan: sedikit demi sedikit, jumlah mereka berkurang setiap bulannya. Para pegawai bank menyadari bahwa akan lebih menghemat biaya jika perusahaan fokus untuk mempertahankan nasabah lama mereka yang setia daripada menarik nasabah baru.\n",
    "\n",
    "Pada kasus ini, tugas kita adalah untuk memprediksi apakah seorang nasabah akan segera meninggalkan bank atau tidak. Dimana kita memiliki data terkait perilaku para klien di masa lalu dan riwayat pemutusan kontrak mereka dengan bank. berdasarkan data ini kita akan membuat model F1 dengan skor setinggi mungkin, dengan minimal nilai F1 0.59 pada test dataset, selain itu kita akan mengukur metrik AUC-ROC dan membandingkan metrik tersebut dengan skor F1 yang kita miliki\n",
    "\n",
    "**Fitur - Fitur\n",
    "- RowNumber — indeks string data\n",
    "- CustomerId — ID pelanggan\n",
    "- Surname — nama belakang\n",
    "- CreditScore — skor kredit\n",
    "- Geography — negara domisili\n",
    "- Gender — gender\n",
    "- Age — umur\n",
    "- Tenure — jangka waktu jatuh tempo untuk deposito tetap nasabah (tahun)\n",
    "- Balance — saldo rekening\n",
    "- NumOfProducts — jumlah produk bank yang digunakan oleh nasabah\n",
    "- HasCrCard — apakah nasabah memiliki kartu kredit (1 - jika ya; 0 - jika tidak)\n",
    "- IsActiveMember — tingkat keaktifan nasabah (1 - jika ya; 0 - jika tidak)\n",
    "- EstimatedSalary — estimasi gaji\n",
    "\n",
    "**Target\n",
    "- Exited — apakah nasabah telah berhenti (1 - jika ya; 0 - jika tidak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sidetable\n",
      "  Downloading sidetable-0.9.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.9/site-packages (from sidetable) (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0->sidetable) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0->sidetable) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0->sidetable) (1.21.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->sidetable) (1.16.0)\n",
      "Installing collected packages: sidetable\n",
      "Successfully installed sidetable-0.9.1\n"
     ]
    }
   ],
   "source": [
    "# Load all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "!pip install sidetable\n",
    "import sidetable as stb\n",
    "import warnings\n",
    "\n",
    "# ml libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('https://practicum-content.s3.us-west-1.amazonaws.com/datasets/Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/content/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>2767</td>\n",
       "      <td>15677217</td>\n",
       "      <td>Ibragimova</td>\n",
       "      <td>705</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181300.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>676</td>\n",
       "      <td>15754605</td>\n",
       "      <td>Jarvis</td>\n",
       "      <td>563</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17603.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>4394</td>\n",
       "      <td>15570051</td>\n",
       "      <td>Gill</td>\n",
       "      <td>775</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>6.0</td>\n",
       "      <td>179886.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153122.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>3812</td>\n",
       "      <td>15589428</td>\n",
       "      <td>Tomlinson</td>\n",
       "      <td>756</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35673.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>442</td>\n",
       "      <td>15611088</td>\n",
       "      <td>Genovese</td>\n",
       "      <td>790</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84126.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "2766       2767    15677217  Ibragimova          705    France    Male   30   \n",
       "675         676    15754605      Jarvis          563    France  Female   39   \n",
       "4393       4394    15570051        Gill          775   Germany  Female   38   \n",
       "3811       3812    15589428   Tomlinson          756    France  Female   42   \n",
       "441         442    15611088    Genovese          790    France  Female   31   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "2766     1.0       0.00              1          1               1   \n",
       "675      5.0       0.00              2          1               1   \n",
       "4393     6.0  179886.41              2          0               0   \n",
       "3811     9.0       0.00              2          1               0   \n",
       "441      9.0       0.00              2          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "2766        181300.32       0  \n",
       "675          17603.81       0  \n",
       "4393        153122.58       0  \n",
       "3811         35673.42       0  \n",
       "441          84126.75       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>missing</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tenure</td>\n",
       "      <td>909</td>\n",
       "      <td>10000</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RowNumber</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CustomerId</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surname</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CreditScore</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Geography</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balance</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumOfProducts</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HasCrCard</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IsActiveMember</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EstimatedSalary</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Exited</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index  missing  total  percent\n",
       "0            Tenure      909  10000     9.09\n",
       "1         RowNumber        0  10000     0.00\n",
       "2        CustomerId        0  10000     0.00\n",
       "3           Surname        0  10000     0.00\n",
       "4       CreditScore        0  10000     0.00\n",
       "5         Geography        0  10000     0.00\n",
       "6            Gender        0  10000     0.00\n",
       "7               Age        0  10000     0.00\n",
       "8           Balance        0  10000     0.00\n",
       "9     NumOfProducts        0  10000     0.00\n",
       "10        HasCrCard        0  10000     0.00\n",
       "11   IsActiveMember        0  10000     0.00\n",
       "12  EstimatedSalary        0  10000     0.00\n",
       "13           Exited        0  10000     0.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying missing values\n",
    "df.stb.missing().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9945</td>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9957</td>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9965</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "30           31    15589475    Azikiwe          591     Spain  Female   39   \n",
       "48           49    15766205        Yin          550   Germany    Male   38   \n",
       "51           52    15768193  Trevisani          585   Germany    Male   36   \n",
       "53           54    15702298   Parkhill          655   Germany    Male   41   \n",
       "60           61    15651280     Hunter          742   Germany    Male   35   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9944       9945    15703923    Cameron          744   Germany    Male   41   \n",
       "9956       9957    15707861      Nucci          520    France  Female   46   \n",
       "9964       9965    15642785    Douglas          479    France    Male   34   \n",
       "9985       9986    15586914     Nepean          659    France    Male   36   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "30       NaN       0.00              3          1               0   \n",
       "48       NaN  103391.38              1          0               1   \n",
       "51       NaN  146050.97              2          0               0   \n",
       "53       NaN  125561.97              1          0               0   \n",
       "60       NaN  136857.00              1          0               0   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9944     NaN  190409.34              2          1               1   \n",
       "9956     NaN   85216.61              1          1               0   \n",
       "9964     NaN  117593.48              2          0               0   \n",
       "9985     NaN  123841.49              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "30          140469.38       1  \n",
       "48           90878.13       0  \n",
       "51           86424.57       0  \n",
       "53          164040.94       1  \n",
       "60           84509.57       0  \n",
       "...               ...     ...  \n",
       "9944        138361.48       0  \n",
       "9956        117369.52       1  \n",
       "9964        113308.29       0  \n",
       "9985         96833.00       0  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[909 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Tenure'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.63\n",
       "1    20.37\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check\n",
    "df['Exited'].value_counts()/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating diagrams\n",
    "plt.figure(figsize=(4,4))\n",
    "splot = sns.countplot(x='Exited', data=df, order=df['Exited'].value_counts().index)\n",
    "plt.xlabel('Is Exited')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Count of Exited')\n",
    "for p in splot.patches:\n",
    "        splot.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in the missing values of the tenure column based on age\n",
    "df['Tenure'] = np.round(df['Tenure'].fillna(df.groupby(['Age'])['Tenure'].transform('mean')))\n",
    "df['Tenure'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>missing</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RowNumber</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CustomerId</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surname</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CreditScore</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geography</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Age</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tenure</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balance</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NumOfProducts</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HasCrCard</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IsActiveMember</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EstimatedSalary</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Exited</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index  missing  total  percent\n",
       "0         RowNumber        0  10000      0.0\n",
       "1        CustomerId        0  10000      0.0\n",
       "2           Surname        0  10000      0.0\n",
       "3       CreditScore        0  10000      0.0\n",
       "4         Geography        0  10000      0.0\n",
       "5            Gender        0  10000      0.0\n",
       "6               Age        0  10000      0.0\n",
       "7            Tenure        0  10000      0.0\n",
       "8           Balance        0  10000      0.0\n",
       "9     NumOfProducts        0  10000      0.0\n",
       "10        HasCrCard        0  10000      0.0\n",
       "11   IsActiveMember        0  10000      0.0\n",
       "12  EstimatedSalary        0  10000      0.0\n",
       "13           Exited        0  10000      0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying missing values\n",
    "df.stb.missing().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat data yang hilang pada kolom 'Tenure' sebanyak 909 atau 9%, kita mengganti nilai yang hilang tersebut dengan 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Separation \n",
    "\n",
    "Membagi dataset menjadi training 70%, validation 15%, test 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the dataset into a training set and a second set\n",
    "train_df, df2 = train_test_split(df, train_size=0.7, random_state=12345)\n",
    "# Separating the remaining 30% for validation and testing\n",
    "val_df, test_df = train_test_split(df2, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7000 entries, 9716 to 4578\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      7000 non-null   int64  \n",
      " 1   Geography        7000 non-null   object \n",
      " 2   Gender           7000 non-null   object \n",
      " 3   Age              7000 non-null   int64  \n",
      " 4   Tenure           7000 non-null   float64\n",
      " 5   Balance          7000 non-null   float64\n",
      " 6   NumOfProducts    7000 non-null   int64  \n",
      " 7   HasCrCard        7000 non-null   int64  \n",
      " 8   IsActiveMember   7000 non-null   int64  \n",
      " 9   EstimatedSalary  7000 non-null   float64\n",
      " 10  Exited           7000 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 656.2+ KB\n",
      "None\n",
      "\n",
      "val_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1500 entries, 9116 to 6895\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      1500 non-null   int64  \n",
      " 1   Geography        1500 non-null   object \n",
      " 2   Gender           1500 non-null   object \n",
      " 3   Age              1500 non-null   int64  \n",
      " 4   Tenure           1500 non-null   float64\n",
      " 5   Balance          1500 non-null   float64\n",
      " 6   NumOfProducts    1500 non-null   int64  \n",
      " 7   HasCrCard        1500 non-null   int64  \n",
      " 8   IsActiveMember   1500 non-null   int64  \n",
      " 9   EstimatedSalary  1500 non-null   float64\n",
      " 10  Exited           1500 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 140.6+ KB\n",
      "None\n",
      "\n",
      "test_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1500 entries, 8606 to 142\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      1500 non-null   int64  \n",
      " 1   Geography        1500 non-null   object \n",
      " 2   Gender           1500 non-null   object \n",
      " 3   Age              1500 non-null   int64  \n",
      " 4   Tenure           1500 non-null   float64\n",
      " 5   Balance          1500 non-null   float64\n",
      " 6   NumOfProducts    1500 non-null   int64  \n",
      " 7   HasCrCard        1500 non-null   int64  \n",
      " 8   IsActiveMember   1500 non-null   int64  \n",
      " 9   EstimatedSalary  1500 non-null   float64\n",
      " 10  Exited           1500 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 140.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checking each set\n",
    "print('train_df:')\n",
    "print(train_df.info())\n",
    "print()\n",
    "\n",
    "print('val_df:')\n",
    "print(val_df.info())\n",
    "print()\n",
    "\n",
    "print('test_df:')\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding Exited from the set\n",
    "train_features = train_df.drop('Exited', axis=1) \n",
    "train_target = train_df['Exited']\n",
    "\n",
    "# val_df\n",
    "val_features = val_df.drop('Exited', axis=1)\n",
    "val_target = val_df['Exited']\n",
    "\n",
    "# test_df\n",
    "test_features = test_df.drop('Exited', axis=1)\n",
    "test_target = test_df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita membuat 'Exited' menjadi target dan yang lain menjadi features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Standardization\n",
    "\n",
    "Kinerja model regresi dipengaruhi oleh perbedaan nilai data, terutama ketika fitur diukur dalam satuan yang berbeda. Sederhananya, model regresi mungkin melihat data dengan angka yang lebih besar memiliki signifikansi yang lebih besar dibandingkan data dengan nilai yang lebih kecil. Dengan melakukan scaling standardization dapat meningkatkan efisiensi model regresi dengan mengubah nilai data menjadi skala yang seragam. Untuk mengantisipasi outlier pada data saat ini dan masa depan, kita akan menggunakan standardization, yaitu metode penskalaan yang umum digunakan dan lebih tahan terhadap outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fitting & transforming training data\n",
    "# Defining a logical slice rule for selecting numerical columns\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "# .values attribute excludes dataframe headers and prevent errors/warnings\n",
    "train_features[numeric] = standard_scaler.fit_transform(X=train_features[numeric].values)\n",
    "\n",
    "# Transforming validation & test sets\n",
    "val_features[numeric] = standard_scaler.transform(X=val_features[numeric].values)\n",
    "test_features[numeric] = standard_scaler.transform(X=test_features[numeric].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "Agar model ML dapat menentukan korelasi antara fitur target dan kategorikal, fitur tersebut perlu dikodekan dengan angka. kita perlu melakukan One Hot Encoding atau OHE terhadap kolom category agar menjadi fitur numerik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>1.658077</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>0.635477</td>\n",
       "      <td>2.527132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480907</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.198643</td>\n",
       "      <td>0.584111</td>\n",
       "      <td>0.352917</td>\n",
       "      <td>0.375870</td>\n",
       "      <td>-0.895510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>-1.374648</td>\n",
       "      <td>0.774530</td>\n",
       "      <td>0.352917</td>\n",
       "      <td>1.302947</td>\n",
       "      <td>0.815811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>-0.784664</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>1.446667</td>\n",
       "      <td>0.696496</td>\n",
       "      <td>-0.895510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2.051400</td>\n",
       "      <td>2.583513</td>\n",
       "      <td>-0.376250</td>\n",
       "      <td>-1.222967</td>\n",
       "      <td>0.815811</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.617269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "9716     1.658077  0.012853 -0.011667  0.635477       2.527132          1   \n",
       "224      0.198643  0.584111  0.352917  0.375870      -0.895510          1   \n",
       "589     -1.374648  0.774530  0.352917  1.302947       0.815811          0   \n",
       "7507    -0.784664  0.488901  1.446667  0.696496      -0.895510          1   \n",
       "1457     2.051400  2.583513 -0.376250 -1.222967       0.815811          0   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "9716               1         1.480907                  1                0   \n",
       "224                1         0.153167                  1                0   \n",
       "589                0         0.817773                  0                1   \n",
       "7507               0         0.329403                  1                0   \n",
       "1457               1        -0.617269                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "9716            1  \n",
       "224             1  \n",
       "589             0  \n",
       "7507            1  \n",
       "1457            1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.get_dummies(train_features, drop_first=True)\n",
    "val_features = pd.get_dummies(val_features, drop_first=True)\n",
    "test_features = pd.get_dummies(test_features, drop_first=True)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Validation\n",
    "\n",
    "Kita akan membuat 3 model dengan hyperparameter yang berbeda, kita akan melatih masing-masing dari tiga model klasifikasi dengan hyperparameter yang bervariasi dan mengevaluasi performanya dalam memprediksi set validasi. Performa model akan diukur berdasarkan skor metrik validation (bukan skor training karena skor tersebut hanya akan meningkat seiring dengan semakin banyaknya pelatihan). Meskipun demikian, skor training yang sesuai akan ditampilkan untuk perbandingan.\n",
    "\n",
    "Pada kasus ini, False Positive dan False Negative sama-sama tidak diinginkan dan akan menimbulkan kerugian besar bagi bank. Kita memerlukan keseimbangan antara kedua metrik ini, jadi kita akan menggunakan metrik yang menggabungkan kedua pengukuran tersebut yakni skor F1. Untuk kemampuan prediksi kelas secara keseluruhan, kita akan menggunakan skor kurva AUC-ROC. Berbeda dengan accuracy, AUC-ROC bekerja dengan baik dengan kumpulan data yang tidak seimbang, seperti yang terjadi pada kasus ini.\n",
    "\n",
    "Dimana bank menetapkan nilai minimal skor F1 adalah 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with imbalance dataset\n",
    "\n",
    "Kita akan melakukan model training dengan data original yang tidak seimbang untuk melihat kinerjanya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "\n",
    "Performa model ini bervariasi berdasarkan kedalaman pohon. Artinya kita harus menjaga pohonnya cukup dalam untuk menghasilkan hasil terbaik, namun tidak terlalu dalam untuk mencegah overfitting dan wasting resources. Untuk mencapai hal ini, kita akan melatih dan memvalidasi model 10 kali dengan kedalaman yang semakin meningkat dan memilih model dengan skor terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3384564260197724"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy = df\n",
    "df_dummy['dummy_pred'] = 1\n",
    "dummy_pred = len(df_dummy.query('dummy_pred == 1 & Exited == 1')) / len(df_dummy)\n",
    "dummy_pred_f1_score = (2 * dummy_pred) / (dummy_pred + 1)\n",
    "dummy_pred_f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 5 \n",
      " training F1 score: 0.5776081424936386 training AUC-ROC score: 0.8425748714919036 \n",
      " validation F1 score: 0.5611222444889779 validation AUC-ROC score: 0.830072818913805\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_best_train_f1 = 0\n",
    "tree_best_train_roc_auc = 0\n",
    "tree_best_val_f1 = 0\n",
    "tree_best_val_roc_auc = 0\n",
    "tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    tree_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training class prediction & correct prediction probability scores\n",
    "    train_pred = tree_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = tree_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    \n",
    "    # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "    val_pred = tree_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = tree_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if (val_f1 > tree_best_val_f1) and (val_roc_auc > tree_best_val_roc_auc):\n",
    "        tree_best_train_f1 = train_f1\n",
    "        tree_best_train_roc_auc = train_roc_auc\n",
    "        tree_best_val_f1 = val_f1 \n",
    "        tree_best_val_roc_auc = val_roc_auc\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best max_depth:', tree_best_depth, '\\n', \n",
    "      'training F1 score:', tree_best_train_f1, 'training AUC-ROC score:', tree_best_train_roc_auc, '\\n',\n",
    "      'validation F1 score:', tree_best_val_f1, 'validation AUC-ROC score:', tree_best_val_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Pada model ini accuracy akan bervariasi tergantung pada max_depth dan jumlah pohon (n_estimators).max_depth akan di aur dari 1-10 dan n_estimators akan berkisar dari 10-100 dengan penambahan 10 estimators pada setiap iterasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training F1 score: 0.6528162511542013 best training AUC-ROC score: 0.9394273123563687 \n",
      " Best validation F1 score: 0.5811965811965811 best validation AUC-ROC score: 0.8587880988720851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=9, n_estimators=60, random_state=12345)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_train_f1 = 0\n",
    "forest_best_train_roc_auc = 0\n",
    "forest_best_val_f1 = 0\n",
    "forest_best_val_roc_auc = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=estimator)\n",
    "        forest_model.fit(train_features, train_target)\n",
    "        \n",
    "        # Getting training class prediction & correct prediction probability scores\n",
    "        train_pred = forest_model.predict(train_features)\n",
    "        train_f1 = f1_score(train_target, train_pred)\n",
    "        train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "        \n",
    "        # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_f1 = f1_score(val_target, val_pred)\n",
    "        val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "        \n",
    "        # Storing the best depth and scores\n",
    "        if (val_f1 > forest_best_val_f1) and (val_roc_auc > forest_best_val_roc_auc):\n",
    "            forest_best_train_f1 = train_f1\n",
    "            forest_best_train_roc_auc = train_roc_auc\n",
    "            forest_best_val_f1 = val_f1 \n",
    "            forest_best_val_roc_auc = val_roc_auc\n",
    "            forest_best_model = forest_model\n",
    "            \n",
    "print('Best training F1 score:', forest_best_train_f1, 'best training AUC-ROC score:', forest_best_train_roc_auc, '\\n',\n",
    "      'Best validation F1 score:', forest_best_val_f1, 'best validation AUC-ROC score:', forest_best_val_roc_auc)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "Pada model ini kita akan membandingkan five slovers yang disediakan oleh sckit-learn. solver sag dan saga membutuhkan banyak iterasi agar dapat berjalan dengan baik, oleh sebab itu kita akan meningkatkan hyperparameter max_iter menjadi 4000, dan tetap menggunakan nilai default 100 untuk yang lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "training F1 score: 0.33126293995859213\n",
      "training AUC-ROC score: 0.9608933666528069\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8570761581538343\n",
      "\n",
      "newton-cg\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9608933666528069\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8570761581538343\n",
      "\n",
      "lbfgs\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9608933666528069\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8570761581538343\n",
      "\n",
      "sag\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9608933666528069\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8570761581538343\n",
      "\n",
      "saga\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9608933666528069\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8570761581538343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, \n",
    "    # changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, \n",
    "                                          solver=solver, max_iter=4000)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver)\n",
    "    logreg_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    print(solver)\n",
    "    print('training F1 score:', train_f1)\n",
    "    print('training AUC-ROC score:', train_roc_auc)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    print('validation F1 score:', val_f1)\n",
    "    print('validation AUC-ROC score:', val_roc_auc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesimpulan melatih model dengan menggunakan imbalanced data :\n",
    "\n",
    "- Decision tree (max_depth = 5):\n",
    "F1: ~0.561,\n",
    "AUC-ROC: ~0.83\n",
    "- Random forest (max_depth=9, n_estimators=60):\n",
    "F1: ~0.586,\n",
    "AUC-ROC: ~0.858\n",
    "- Logistic regression (any solver):\n",
    "F1: ~0.319,\n",
    "AUC-ROC: ~0.857\n",
    "\n",
    "Tidak ada model yang melewati nilai minimal F1 : 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing imbalance dataset\n",
    "\n",
    "Menyeimbangkan data dapat mengurangi bias yang ditimbulkan oleh class proportions yang tidak seimbang, yang mana akan meningkatkan performa model, Kita akan mencoba beberapa pendekatan untuk dapat menyeimbangkan data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5589\n",
      "1    1411\n",
      "Name: Exited, dtype: int64\n",
      "0    0.798429\n",
      "1    0.201571\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_target.value_counts(normalize=False))\n",
    "print(train_target.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Weight \n",
    "\n",
    "kita akan menggunakan pendekatan menambahkan hyperparameter class_weight = 'balance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 5 \n",
      " training F1 score: 0.5850257653834495 training AUC-ROC score: 0.8467621868865377 \n",
      " validation F1 score: 0.5958041958041959 validation AUC-ROC score: 0.8382543665409788\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_best_train_f1 = 0\n",
    "tree_best_train_roc_auc = 0\n",
    "tree_best_val_f1 = 0\n",
    "tree_best_val_roc_auc = 0\n",
    "tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345, class_weight='balanced')\n",
    "    tree_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training class prediction & correct prediction probability scores\n",
    "    train_pred = tree_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = tree_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    \n",
    "    # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "    val_pred = tree_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = tree_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if (val_f1 > tree_best_val_f1) and (val_roc_auc > tree_best_val_roc_auc):\n",
    "        tree_best_train_f1 = train_f1\n",
    "        tree_best_train_roc_auc = train_roc_auc\n",
    "        tree_best_val_f1 = val_f1 \n",
    "        tree_best_val_roc_auc = val_roc_auc\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best max_depth:', tree_best_depth, '\\n', \n",
    "      'training F1 score:', tree_best_train_f1, 'training AUC-ROC score:', tree_best_train_roc_auc, '\\n',\n",
    "      'validation F1 score:', tree_best_val_f1, 'validation AUC-ROC score:', tree_best_val_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training F1 score: 0.7008601465434852 best training AUC-ROC score: 0.9221693061913278 \n",
      " Best validation F1 score: 0.6499999999999999 best validation AUC-ROC score: 0.8585642086984061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=8, n_estimators=60,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_train_f1 = 0\n",
    "forest_best_train_roc_auc = 0\n",
    "forest_best_val_f1 = 0\n",
    "forest_best_val_roc_auc = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, \n",
    "                                              n_estimators=estimator, class_weight='balanced')\n",
    "        forest_model.fit(train_features, train_target)\n",
    "        \n",
    "        # Getting training class prediction & correct prediction probability scores\n",
    "        train_pred = forest_model.predict(train_features)\n",
    "        train_f1 = f1_score(train_target, train_pred)\n",
    "        train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "        \n",
    "        # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_f1 = f1_score(val_target, val_pred)\n",
    "        val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "        \n",
    "        # Storing the best depth and scores\n",
    "        if (val_f1 > forest_best_val_f1) and (val_roc_auc > forest_best_val_roc_auc):\n",
    "            forest_best_train_f1 = train_f1\n",
    "            forest_best_train_roc_auc = train_roc_auc\n",
    "            forest_best_val_f1 = val_f1 \n",
    "            forest_best_val_roc_auc = val_roc_auc\n",
    "            forest_best_model = forest_model\n",
    "            \n",
    "print('Best training F1 score:', forest_best_train_f1, 'best training AUC-ROC score:', forest_best_train_roc_auc, '\\n',\n",
    "      'Best validation F1 score:', forest_best_val_f1, 'best validation AUC-ROC score:', forest_best_val_roc_auc)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "training F1 score: 0.33126293995859213\n",
      "training AUC-ROC score: 0.9674340061772142\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8604563537027887\n",
      "\n",
      "newton-cg\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9674340061772142\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8604563537027887\n",
      "\n",
      "lbfgs\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9674340061772142\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8604563537027887\n",
      "\n",
      "sag\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9674340061772142\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8604563537027887\n",
      "\n",
      "saga\n",
      "training F1 score: 0.33039875712066286\n",
      "training AUC-ROC score: 0.9674340061772142\n",
      "validation F1 score: 0.31999999999999995\n",
      "validation AUC-ROC score: 0.8604563537027887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, \n",
    "    # changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, \n",
    "                                          solver=solver, max_iter=4000)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver)\n",
    "    logreg_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    print(solver)\n",
    "    print('training F1 score:', train_f1)\n",
    "    print('training AUC-ROC score:', train_roc_auc)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    print('validation F1 score:', val_f1)\n",
    "    print('validation AUC-ROC score:', val_roc_auc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesimpulan melatih model dengan menggunakan pendekatan class weight :\n",
    "\n",
    "- Decision tree (max_depth = 5):\n",
    "F1: ~0.595,\n",
    "AUC-ROC: ~0.838\n",
    "- Random forest (max_depth=8, n_estimators=60):\n",
    "F1: ~0.649,\n",
    "AUC-ROC: ~0.858\n",
    "- Logistic regression (any solver):\n",
    "F1: ~0.319,\n",
    "AUC-ROC: ~0.86\n",
    "\n",
    "Hanya model logistic regression yang tidak melewati nilai minimal F1 : 0.59, dengan model random forest memiliki skor F1 tertinggi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling\n",
    "\n",
    "Dengan menggunakan pendekatan upsampling, kita nilai 'excited=1' agar nilainya mendekati 'excited=0' yang mana jumlahnya sangat banyak, Kemudian kita harus mengacak data untuk mencegah bias pembelajaran.\n",
    "\n",
    "Scikit-learn tidak memiliki fungsi bawaan untuk metode ini, jadi kita harus mendefinisikan sendiri fungsinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 observances in original training set: 1411\n",
      "Class 1 observances in upsampled training set: 4233\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, upsample_one, repeat, random_state):\n",
    "\n",
    "    # Separating features and targets of each class\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # Choosing which class observations to upsample\n",
    "    if upsample_one == True:\n",
    "        features_upsampled = pd.concat([features_zeros] + \n",
    "                                       [features_ones] * repeat)\n",
    "        target_upsampled = pd.concat([target_zeros] + \n",
    "                                     [target_ones] * repeat)\n",
    "    else:\n",
    "        features_upsampled = pd.concat([features_ones] + \n",
    "                                       [features_zeros] * repeat)\n",
    "        target_upsampled = pd.concat([target_ones] + \n",
    "                                     [target_zeros] * repeat)\n",
    "    \n",
    "    # Shuffling data\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                   target_upsampled, \n",
    "                                                   random_state=random_state)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "# Upsampling the training set 4 times\n",
    "features_upsampled, target_upsampled = upsample(train_features,\n",
    "                                                train_target,\n",
    "                                                upsample_one=True,\n",
    "                                                repeat=3,\n",
    "                                                random_state=12345)\n",
    "\n",
    "print(f'Class 1 observances in original training set: {len(train_features[train_target == 1])}',\n",
    "      f'Class 1 observances in upsampled training set: {len(features_upsampled[target_upsampled == 1])}',\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class count:\n",
      "0    5589\n",
      "1    1411\n",
      "Name: Exited, dtype: int64\n",
      "Upsampled set class count:\n",
      "0    5589\n",
      "1    4233\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training set class count:', train_target.value_counts(), sep='\\n')\n",
    "print('Upsampled set class count:', target_upsampled.value_counts(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 5 \n",
      " training F1 score: 0.7102924127270386 training AUC-ROC score: 0.8467621868865377 \n",
      " validation F1 score: 0.6051437216338881 validation AUC-ROC score: 0.8382598272769222\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_best_train_f1 = 0\n",
    "tree_best_train_roc_auc = 0\n",
    "tree_best_val_f1 = 0\n",
    "tree_best_val_roc_auc = 0\n",
    "upsampled_tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    tree_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # Getting training class prediction & correct prediction probability scores\n",
    "    train_pred = tree_model.predict(features_upsampled)\n",
    "    train_f1 = f1_score(target_upsampled, train_pred)\n",
    "    train_proba = tree_model.predict_proba(features_upsampled)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(target_upsampled, train_proba)\n",
    "    \n",
    "    # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "    val_pred = tree_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = tree_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if (val_f1 > tree_best_val_f1) and (val_roc_auc > tree_best_val_roc_auc):\n",
    "        tree_best_train_f1 = train_f1\n",
    "        tree_best_train_roc_auc = train_roc_auc\n",
    "        tree_best_val_f1 = val_f1 \n",
    "        tree_best_val_roc_auc = val_roc_auc\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best max_depth:', tree_best_depth, '\\n', \n",
    "      'training F1 score:', tree_best_train_f1, 'training AUC-ROC score:', tree_best_train_roc_auc, '\\n',\n",
    "      'validation F1 score:', tree_best_val_f1, 'validation AUC-ROC score:', tree_best_val_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training F1 score: 0.8353383458646617 best training AUC-ROC score: 0.945546576441854 \n",
      " Best validation F1 score: 0.6454689984101749 best validation AUC-ROC score: 0.8613874091811353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=9, n_estimators=90, random_state=12345)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_train_f1 = 0\n",
    "forest_best_train_roc_auc = 0\n",
    "forest_best_val_f1 = 0\n",
    "forest_best_val_roc_auc = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=estimator)\n",
    "        forest_model.fit(features_upsampled, target_upsampled)\n",
    "        \n",
    "        # Getting training class prediction & correct prediction probability scores\n",
    "        train_pred = forest_model.predict(features_upsampled)\n",
    "        train_f1 = f1_score(target_upsampled, train_pred)\n",
    "        train_proba = forest_model.predict_proba(features_upsampled)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(target_upsampled, train_proba)\n",
    "        \n",
    "        # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_f1 = f1_score(val_target, val_pred)\n",
    "        val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "        \n",
    "        # Storing the best depth and scores\n",
    "        if (val_f1 > forest_best_val_f1) and (val_roc_auc > forest_best_val_roc_auc):\n",
    "            forest_best_train_f1 = train_f1\n",
    "            forest_best_train_roc_auc = train_roc_auc\n",
    "            forest_best_val_f1 = val_f1 \n",
    "            forest_best_val_roc_auc = val_roc_auc\n",
    "            forest_best_model = forest_model\n",
    "            \n",
    "print('Best training F1 score:', forest_best_train_f1, 'best training AUC-ROC score:', forest_best_train_roc_auc, '\\n',\n",
    "      'Best validation F1 score:', forest_best_val_f1, 'best validation AUC-ROC score:', forest_best_val_roc_auc)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "training F1 score: 0.636769015161167\n",
      "training AUC-ROC score: 0.9676124218385334\n",
      "validation F1 score: 0.5118110236220472\n",
      "validation AUC-ROC score: 0.8589000439589244\n",
      "\n",
      "newton-cg\n",
      "training F1 score: 0.636769015161167\n",
      "training AUC-ROC score: 0.9676124218385334\n",
      "validation F1 score: 0.5118110236220472\n",
      "validation AUC-ROC score: 0.8589000439589244\n",
      "\n",
      "lbfgs\n",
      "training F1 score: 0.636769015161167\n",
      "training AUC-ROC score: 0.9676124218385334\n",
      "validation F1 score: 0.5118110236220472\n",
      "validation AUC-ROC score: 0.8589000439589244\n",
      "\n",
      "sag\n",
      "training F1 score: 0.636769015161167\n",
      "training AUC-ROC score: 0.9676124218385334\n",
      "validation F1 score: 0.5118110236220472\n",
      "validation AUC-ROC score: 0.8589000439589244\n",
      "\n",
      "saga\n",
      "training F1 score: 0.636769015161167\n",
      "training AUC-ROC score: 0.9676124218385334\n",
      "validation F1 score: 0.5118110236220472\n",
      "validation AUC-ROC score: 0.8589000439589244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, \n",
    "    # changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver, max_iter=4000)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver)\n",
    "    logreg_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(features_upsampled)\n",
    "    train_f1 = f1_score(target_upsampled, train_pred)\n",
    "    train_proba = forest_model.predict_proba(features_upsampled)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(target_upsampled, train_proba)\n",
    "    print(solver)\n",
    "    print('training F1 score:', train_f1)\n",
    "    print('training AUC-ROC score:', train_roc_auc)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    print('validation F1 score:', val_f1)\n",
    "    print('validation AUC-ROC score:', val_roc_auc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kesimpulan melatih model dengan menggunakan pendekatan upsampling :\n",
    "\n",
    "- Decision tree (max_depth = 5):\n",
    "F1: ~0.605,\n",
    "AUC-ROC: ~0.838\n",
    "- Random forest (max_depth=9, n_estimators=90):\n",
    "F1: ~0.645,\n",
    "AUC-ROC: ~0.861\n",
    "- Logistic regression (any solver):\n",
    "F1: ~0.511,\n",
    "AUC-ROC: ~0.858\n",
    "\n",
    "Hanya model logistic regression yang tetap tidak dapat tidak melewati nilai minimal F1 : 0.59, dengan tetap model random forest memiliki skor F1 tertinggi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conclusion\n",
    "\n",
    "Dengan menggunakan 3 pendekatan berbeda untuk melatih model kita dapat menarik kesimpulan :\n",
    "\n",
    "- Model terbaik dengan menggunakan imbalance dataset\n",
    "Random forest (max_depth=9, n_estimators=60):\n",
    "F1: ~0.586,\n",
    "AUC-ROC: ~0.858\n",
    "- Model terbaik dengan pendekatan class weight\n",
    "Random forest (max_depth=8, n_estimators=60):\n",
    "F1: ~0.649,\n",
    "AUC-ROC: ~0.858\n",
    "- Model terbaik dengan pendekatan upsampling\n",
    "Random forest (max_depth=9, n_estimators=90):\n",
    "F1: ~0.645,\n",
    "AUC-ROC: ~0.861\n",
    "\n",
    "Kedua model random forest terakhir melebihi batas minimum nilai skor F1 0.59, Pendekatan class weight memiliki nilai F1 lebih tinggi, tetapi nilai AUC-ROC lebih rendah dari pendekatan upsampling.\n",
    "\n",
    "Kita memutuskan untuk menggunakan model random forest dengan pendekatan class weight karena kita menilai lebih baik dari model yang lain karena skor F1 yang paling tinggi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score: 0.6323529411764706\n",
      "Test AUC-ROC score: 0.8577821781126987\n"
     ]
    }
   ],
   "source": [
    "# Combining training and validation sets\n",
    "final_features = pd.concat([train_features] + [val_features])\n",
    "final_target = pd.concat([train_target] + [val_target])\n",
    "\n",
    "# Creating and training model\n",
    "final_model = RandomForestClassifier(max_depth=9, n_estimators=20, class_weight='balanced', random_state=12345)\n",
    "final_model.fit(final_features, final_target)\n",
    "\n",
    "# Testing\n",
    "test_pred = final_model.predict(test_features)\n",
    "test_f1 = f1_score(test_target, test_pred)\n",
    "\n",
    "test_proba = final_model.predict_proba(test_features)[:, 1]\n",
    "test_roc_auc = roc_auc_score(test_target, test_proba)\n",
    "\n",
    "print('Test F1 score:', test_f1)\n",
    "print('Test AUC-ROC score:', test_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meskipun ada sedikit penurunan skor, model ini berhasil dalam testing, melampaui skor dasar dengan F1 sebesar 0,632 dan skor AUC-ROC sebesar 0,857."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Conclusion\n",
    "\n",
    "Beberapa langkah yang telah kita lakukan untuk memproses data pada tugas ini :\n",
    "\n",
    "- Mengganti nilai yang hilang pada Tenure dengan 0\n",
    "- Mendrop features yang tidak relevan\n",
    "- Membagi full dataset menjadi training, validation, dan test\n",
    "- Pemisahan lebih lanjut menjadi set features dan target\n",
    "- Melakukan penskalaan pada numeric values dengan standardization\n",
    "- Melakukan One hot encoding\n",
    "- Melakukan training model pada data yang imbalance dengan berbagai pendekatan sehingga bisa menghasilkan model terbaik yakni pendekatan class weight\n",
    "\n",
    "Model akhir yang akain kita gunakan untuk menyelesaikan tugas untuk memprediksi apakah seorang nasabah akan segera meninggalkan bank atau tidak adalah random forest classifier dengan hyperparameter :\n",
    "\n",
    "max_depth = 8\n",
    "n_estimators = 60\n",
    "class_weight = 'balanced'\n",
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Chamdani's comment v.1</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Hebat, Kerja bagus!\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
